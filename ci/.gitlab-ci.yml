stages:
  - compile
  - python
  - test
  - static-test
  - docs
  - publish

image: $CI_REGISTRY/cps/rapid-prototyping-setup/ci-lite:1.0

before_script:
  - git config --global url."https://gitlab-ci-token:${CI_JOB_TOKEN}@gitlab.lrz.de/".insteadOf "git@gitlab.lrz.de:"
  - git config --global url."https://gitlab-ci-token:${CI_JOB_TOKEN}@gitlab.lrz.de".insteadOf "ssh://git@gitlab.lrz.de"

### static test ###
clang-format:
  image: $CI_REGISTRY/cps/rapid-prototyping-setup/ci:1.4
  stage: static-test
  script: ./ci/clang-format.sh
  needs: []

clang-tidy:
  image: $CI_REGISTRY/cps/rapid-prototyping-setup/ci:1.4
  stage: static-test
  script: ./ci/clang-tidy.sh
  needs:
    - job: build-compile-commands
      artifacts: true

cppcheck:
  stage: static-test
  script:
    cppcheck
    --project=build/compile_commands.json
    -i"$(pwd)/external"
  needs:
    - job: build-compile-commands
      artifacts: true

.cache-build-dir:
  cache: &cache_dependency_archives
    key: cache-dependency-archives
    paths:
      - build/_deps/*-subbuild/*-populate-prefix/src/*.{tar*,zip}
    policy: pull

generate-cache:
  stage: compile
  cache:
    <<: *cache_dependency_archives
    policy: push
  script:
    - cmake -G "Ninja Multi-Config" -S . -B build -DFETCHCONTENT_QUIET:BOOL=OFF
  needs: []

### build project ###
build-compile-commands:
  stage: compile
  script:
    # run CMake in order to get compile_commands.json
    - mkdir build && cd build
    - cmake -DCMAKE_INSTALL_PREFIX=/commonroad/dist -DCMAKE_BUILD_TYPE=Debug -DCMAKE_EXPORT_COMPILE_COMMANDS=ON  ..
    - cd ..
  needs: []
  artifacts:
    paths:
      - ./build/compile_commands.json
    expire_in: 20 minutes

build-clang:
  stage: compile
  cache:
    <<: *cache_dependency_archives
  variables:
    CC: clang
    CXX: clang++
  script:
    - printf "\e[0Ksection_start:%s:%s\r\e[0K%s\n" "$(date +%s)"
      section_config "CMake Configuration"
    - cmake -G "Ninja Multi-Config" -S . -B build
    - printf "\e[0Ksection_end:%s:%s\r\e[0K\n" "$(date +%s)"
      section_config
    - printf "\e[0Ksection_start:%s:%s\r\e[0K%s\n" "$(date +%s)"
      section_build "CMake Build"
    - cmake --build build --config Release
    - printf "\e[0Ksection_end:%s:%s\r\e[0K\n" "$(date +%s)"
      section_build
  needs: []

build-gcc:
  stage: compile
  cache:
    <<: *cache_dependency_archives
  variables:
    CC: gcc
    CXX: g++
  script:
    - printf "\e[0Ksection_start:%s:%s\r\e[0K%s\n" "$(date +%s)"
      section_config "CMake Configuration"
    - cmake -G "Ninja Multi-Config" -S . -B build
    - printf "\e[0Ksection_end:%s:%s\r\e[0K\n" "$(date +%s)"
      section_config
    - printf "\e[0Ksection_start:%s:%s\r\e[0K%s\n" "$(date +%s)"
      section_build "CMake Build"
    - cmake --build build --config Release
    - printf "\e[0Ksection_end:%s:%s\r\e[0K\n" "$(date +%s)"
      section_build
  needs: []

build-standalone:
  stage: compile
  cache:
    <<: *cache_dependency_archives
  script:
    - printf "\e[0Ksection_start:%s:%s\r\e[0K%s\n" "$(date +%s)"
      section_config "CMake Configuration"
    - cmake -G "Ninja Multi-Config" -S . -B build
    - printf "\e[0Ksection_end:%s:%s\r\e[0K\n" "$(date +%s)"
      section_config
    - printf "\e[0Ksection_start:%s:%s\r\e[0K%s\n" "$(date +%s)"
      section_build "CMake Build"
    - cmake --build build --config Release --target env_model_example_node
    - printf "\e[0Ksection_end:%s:%s\r\e[0K\n" "$(date +%s)"
      section_build
  needs: []

build-test:
  stage: compile
  cache:
    <<: *cache_dependency_archives
  script:
    - printf "\e[0Ksection_start:%s:%s\r\e[0K%s\n" "$(date +%s)"
      section_config "CMake Configuration"
    - cmake -G "Ninja Multi-Config" -S . -B build
    - printf "\e[0Ksection_end:%s:%s\r\e[0K\n" "$(date +%s)"
      section_config
    - printf "\e[0Ksection_start:%s:%s\r\e[0K%s\n" "$(date +%s)"
      section_build "CMake Build"
    - cmake --build build --config RelWithDebInfo --target env_model_test
    - printf "\e[0Ksection_end:%s:%s\r\e[0K\n" "$(date +%s)"
      section_build
  needs: []
  artifacts:
    paths:
      - build
    expire_in: 30 minutes

build-coverage:
  stage: compile
  cache:
    <<: *cache_dependency_archives
  script:
    - printf "\e[0Ksection_start:%s:%s\r\e[0K%s\n" "$(date +%s)"
      section_config "CMake Configuration"
    - cmake -G "Ninja Multi-Config" -S . -B build -DENV_MODEL_BUILD_CODE_COVERAGE=ON
    - printf "\e[0Ksection_end:%s:%s\r\e[0K\n" "$(date +%s)"
      section_config
    - printf "\e[0Ksection_start:%s:%s\r\e[0K%s\n" "$(date +%s)"
      section_build "CMake Build"
    - cmake --build build --config RelWithDebInfo --target env_model_test
    - printf "\e[0Ksection_end:%s:%s\r\e[0K\n" "$(date +%s)"
      section_build
  needs: []
  artifacts:
    paths:
      - build
    expire_in: 30 minutes

build-nix:
  stage: compile
  image: nixos/nix:latest
  script:
    - nix --extra-experimental-features "nix-command flakes" --print-build-logs build

build-sdist:
  stage: python
  image: $CI_REGISTRY/cps/rapid-prototyping-setup/wheelenv:1.0
  script:
    - python3 --version
    - git describe
    - python3 -m build --sdist
  needs: []
  variables:
    # Necessary so that Git detects all tags
    GIT_STRATEGY: clone
    GIT_DEPTH: 0
    GIT_FETCH_EXTRA_FLAGS: --tags
  artifacts:
    paths:
      - dist/*.tar.gz
    expire_in: 30 minutes

.common-rules:
  rules:
    # Rule to disable a job for merge request pipelines (imitate default job behaviour)
    - &skip_merge_request_pipeline
      if: $CI_PIPELINE_SOURCE == "merge_request_event"
      when: never
    - if: &full_wheel_build_condition $CI_COMMIT_TAG || $CI_COMMIT_REF_PROTECTED == "true" || $CI_COMMIT_REF_NAME == $CI_DEFAULT_BRANCH || $CI_COMMIT_REF_NAME =~ /^(master|develop)$/

build-wheel:
  stage: python
  # Use the privileged runner as required for Docker-in-Docker (dind)
  tags:
    - wheel
  image: $CI_REGISTRY/cps/rapid-prototyping-setup/wheelenv:1.0
  # make a docker daemon available for cibuildwheel to use
  services:
    - name: docker:20.10-dind
      entrypoint: ["env", "-u", "DOCKER_HOST"]
      command: ["dockerd-entrypoint.sh"]
  variables:
    DOCKER_HOST: tcp://docker:2375/
    DOCKER_DRIVER: overlay2
    # See https://github.com/docker-library/docker/pull/166
    DOCKER_TLS_CERTDIR: ""
    CIBW_BEFORE_ALL: "git config --global url.\"https://gitlab-ci-token:${CI_JOB_TOKEN}@gitlab.lrz.de\".insteadOf \"git@gitlab.lrz.de:\" && git config --global url.\"https://gitlab-ci-token:${CI_JOB_TOKEN}@gitlab.lrz.de/\".insteadOf \"ssh://git@gitlab.lrz.de\""
    # NOTE: The following variables correspond to the default values.
    # They are specified here so that it is possible to override them using
    # Gitlab push options or in the UI when running a manual pipeline.
    #
    # For example, use git push -o ci.variable="CIBW_BUILD_VERBOSITY=1"
    # to make cibuildwheel verbose in the pipeline created for the pushed commit.
    CIBW_BUILD_VERBOSITY: 0
    CIBW_TEST_SKIP: "*i686 *-musllinux*"
    # We only use the artifacts (sdist/wheels) from previous jobs, so skip all Git operations
    GIT_STRATEGY: none
  script:
    - cibuildwheel dist/*.tar.gz
  needs:
    - job: build-sdist
      artifacts: true
  artifacts:
    paths:
      - wheelhouse/*.whl
    expire_in: 30 minutes
  rules:
    - *skip_merge_request_pipeline
    # When we are building wheels for a tag/release, build wheel for all supported Python versions and platform
    # Also routinely build all wheels for the default branch as well as develop (commits on these branches are infrequent)
    - if: *full_wheel_build_condition
      variables:
        CIBW_BUILD: "*"
    # Fallback rule when we're not building wheels for a tag or a main branch:
    # In that case, build only a single wheel to speed up the pipeline
    - when: on_success
      variables:
        CIBW_BUILD: "cp310-manylinux_x86_64"

upload-wheel:
  stage: python
  image: $CI_REGISTRY/cps/rapid-prototyping-setup/wheelenv:1.0
  variables:
    TWINE_USERNAME: gitlab-ci-token
    TWINE_PASSWORD: ${CI_JOB_TOKEN}
    TWINE_REPOSITORY_URL: ${CI_API_V4_URL}/projects/${CI_PROJECT_ID}/packages/pypi
    UPLOAD_WHEELS: "0"
    # We only use the artifacts (sdist/wheels) from previous jobs, so skip all Git operations
    GIT_STRATEGY: none
  script:
    - twine upload dist/*.tar.gz wheelhouse/*.whl
  needs:
    - job: build-sdist
      artifacts: true
    - job: build-wheel
      artifacts: true
  rules:
    # Disable job for merge request pipelines (imitate default job behaviour)
    - *skip_merge_request_pipeline
    # Only upload wheels whenever a tag is associated with the commit
    - if: $CI_COMMIT_TAG
    # Also upload wheels if the UPLOAD_WHEELS was manually set to true
    # For example, use git push -o ci.variable="UPLOAD_WHEELS=1" to test this
    - if: $UPLOAD_WHEELS == "1"

### tests ###
test:
  stage: test
  script:
    - cmake --build build --config RelWithDebInfo --target test
  needs:
    - job: build-test
      artifacts: true
  artifacts:
    # Upload reports even if tests fail
    when: always
    reports:
      junit: build/test-reports/*.xml
    expire_in: 30 minutes

run-coverage:
  stage: test
  script:
    - cmake --build build --config RelWithDebInfo --target env_model_coverage
    - gcovr --version
    - gcovr
      -f src/
      -e build/
      --print-summary
      --exclude-unreachable-branches
      --output coverage.xml
      --xml
    - mv build/env_model_coverage coverage-report
  needs:
    - job: build-coverage
      artifacts: true
  coverage: /^\s*lines:\s*\d+.\d+\%/
  artifacts:
    paths:
      - coverage-report
    expose_as: 'Coverage Report'
    expire_in: 30 minutes
    reports:
      coverage_report:
          coverage_format: cobertura
          path: coverage.xml

.test-python-common: &test-python-common
  stage: test
  image: python:${JOB_PYTHON_VERSION}-slim-bullseye
  before_script:
    # Due to security concerns it is not recommended to mix pip commands
    # that download from PyPI with pip commands that should ignore PyPI.
    # At the same time, pip does not support installing only the dependencies.
    # Therefore, we first extract the test dependencies to a temporary requirements
    # file and then instruct pip to install them from that file.
    # Finally, we install the built wheel from the wheelhouse directory.
    - apt-get update && apt-get install -y --no-install-recommends git
    - git config --global url."https://gitlab-ci-token:${CI_JOB_TOKEN}@gitlab.lrz.de/".insteadOf "git@gitlab.lrz.de:"
    - git config --global url."https://gitlab-ci-token:${CI_JOB_TOKEN}@gitlab.lrz.de".insteadOf "ssh://git@gitlab.lrz.de"
    - printf "\e[0Ksection_start:%s:%s[collapsed=true]\r\e[0K%s\n" "$(date +%s)"
      section_python_prep "Installation of test dependencies"
    - python -m pip config set global.disable-pip-version-check true
    - python -m venv test-venv
    - source test-venv/bin/activate
    - python -m pip install pip-tools poetry-core # poetry only needed temporary as long as cr-io feature branch is used
    - SETUPTOOLS_SCM_PRETEND_VERSION_FOR_COMMONROAD_CPP=1
      python -m piptools compile --extra=test -o test_requirements.txt pyproject.toml
    - python -m pip install -r test_requirements.txt
    - python -m pip install --no-index --find-links=wheelhouse/ commonroad_cpp[test]
    - printf "\e[0Ksection_end:%s:%s\r\e[0K\n" "$(date +%s)"
      section_python_prep
  script:
    - python -m pytest --junit-xml=pytest-report.xml tests/python
  needs:
    - job: build-wheel
      artifacts: true
  artifacts:
    reports:
      junit: pytest-report.xml
    expire_in: 30 minutes

.test-python-single: &test-python-single
  variables:
    JOB_PYTHON_VERSION: "3.10"
  rules:
    - *skip_merge_request_pipeline
    - if: *full_wheel_build_condition
      when: never
    - when: on_success

.test-python-matrix: &test-python-matrix
  parallel:
    matrix:
      - JOB_PYTHON_VERSION: ["3.9", "3.10", "3.11"]
  rules:
    - *skip_merge_request_pipeline
    - if: *full_wheel_build_condition
      when: on_success
    - when: never

test-python-manylinux-single:
  <<: [ *test-python-common, *test-python-single ]
  variables:
    JOB_PYTHON_VERSION: "3.10"

test-python-manylinux:
  <<: [ *test-python-common, *test-python-matrix ]


### create documentation ###
docs:
  stage: docs
  script:
    - printf "\e[0Ksection_start:%s:%s\r\e[0K%s\n" "$(date +%s)"
      section_config "CMake Configuration"
    - cmake -G "Ninja Multi-Config" -S . -B build -DENV_MODEL_BUILD_DOXYGEN=ON
    - printf "\e[0Ksection_end:%s:%s\r\e[0K\n" "$(date +%s)"
      section_config
    - printf "\e[0Ksection_start:%s:%s\r\e[0K%s\n" "$(date +%s)"
      section_build "CMake Build"
    - cmake --build build --config RelWithDebInfo --target doc_doxygen
    - printf "\e[0Ksection_end:%s:%s\r\e[0K\n" "$(date +%s)"
      section_build
  needs: []
  artifacts:
    paths:
      - build/doc_doxygen/html/
    expose_as: 'Doxygen Documentation'
    expire_in: 30 minutes

pages:
  stage: publish
  script:
    - mv build/doc_doxygen/html public
  needs:
    - job: docs
      artifacts: true
  artifacts:
    paths:
      - public
    expire_in: 20 minutes
  rules:
    - if: '$CI_COMMIT_BRANCH == "master"'
